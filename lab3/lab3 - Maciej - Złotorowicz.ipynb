{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja Logistyczna\n",
    "\n",
    "Zadanie regresji logistycznej polega na przewidywaniu **prawdopodobieństwa że dana próbka należy do danej klasy**. Czyli wynikiem działania takiego modelu jest liczba z przedziału $[0,1]$.\n",
    "\n",
    "Przykładowo zadanie klasyfikując czy student zda egzamin na podstawie ilości godzin spędzonych na studiowaniu\n",
    "\n",
    "| Ilość godzin    | 0.25 | 1 | 2.4 | 2.5 | 3 | 3.2 | 4 | 4.5 | 5 |\n",
    "|-----------------|------|---|-----|-----|---|-----|---|-----|---|\n",
    "| Zdanie Egzaminu | 0    | 0 | 0   | 1   | 0 | 1   | 1 | 1   | 1 |\n",
    "\n",
    "Aby zmapować przestrzeń liczb rzeczywistych na przedział $[0,1]$ używamy funkcji sigmoidalnej\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
    "$$ \n",
    "Jest to bardzo popularna funkcja która dla skaranie wysokich/niskich wartości zwraca $0$ albo $1$ (\"Nasyca się\") i $0.5$ dla wartości bliskich zeru.\n",
    "\n",
    "Funkcja $e^{-x} + 1$ dąży do $1$ dla $x \\to \\infty$ i $e^x + 1$ dąży do $\\infty$ dla $x \\to -\\infty$. To sprawia że odwrotność tej funkcji dąży do $1/1=1$ dla $x \\to \\infty$ i $1/\\infty=0$ dla $x \\to -\\infty$.\n",
    "\n",
    "Wartości tej funkcji można traktować jak prawdopodobieństwa przynależenia danej próbki do klasy. W przypadku wielu klas należy wytrenować kilka klasyfikatorów rozpoznająchc prawdopodobieństwo przynależenia do danej klasy i wybrać tę klasę która ma największe prawdopodobieństwo.\n",
    "\n",
    "Jest ona przedstawiona na poniższym wykresie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23102dd3a30>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "sig = lambda x: 1 / (1 + np.exp(-x))\n",
    "plt.grid()\n",
    "plt.yticks(np.arange(0, 1.5, 0.5))\n",
    "plt.title(\"σ(x)\", fontsize=20)\n",
    "plt.plot(x, sig(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do obliczenia gradientów potrzebna jest pochodna funkcji $\\sigma(x)$ którą można łatwo obliczyć korzystając między innymi z tych dwóch twierdzeń:\n",
    "* $[\\frac{1}{u(x)}]' = -u(x)^{-2}u'(x)$\n",
    "* $e^{u(x)} = u'(x)*e^{u(x)}$\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "\\sigma'(x) & = \\frac{\\partial }{\\partial x}\\sigma (x) = \\frac{\\partial}{\\partial x} (1+e^{-x})^{-1} \\\\\n",
    "\\sigma'(x) & = -(1+e^{-x})^{-2} \\cdot \\frac{\\partial}{\\partial x} (1+e^{-x}) \\\\\n",
    "\\sigma'(x) & = -(1+e^{-x})^{-2} \\cdot (-e^{-x}) \\\\\n",
    "\\sigma'(x) & = \\frac{e^{-x}}{(1+e^{-x})^2} \\\\\n",
    "\\sigma'(x) & = \\frac{1}{1+e^{-x}} \\cdot \\frac{e^{-x}}{1+e^{-x}} \\\\\n",
    "\\sigma'(x) & = \\frac{1}{1+e^{-x}} \\cdot \\frac{1+e^{-x}-1}{1+e^{-x}} \\\\\n",
    "\\sigma'(x) & = \\frac{1}{1+e^{-x}} \\cdot (\\frac{1+e^{-x}}{1+e^{-x}} + \\frac{1}{1+e^{-x}}) \\\\\n",
    "\\sigma'(x) & = \\frac{1}{1+e^{-x}} \\cdot (1 + \\frac{1}{1+e^{-x}}) \\\\\n",
    "\\sigma'(x) & = \\sigma(x) \\cdot (1-\\sigma(x))\n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "Pochodna tej funkcji jest bardzo prosta i do jej obliczenia potrzebna jest wartość samej funkcji i to w jedym punkcie, więc obliczenie pochodnej wymaga jedynie jednego wywołania funkcji sigmoidalnej.\n",
    "\n",
    "Niżej przedstawiono wykres pochodnej funkcji sigmoidalnej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23102e1e7c0>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.title(\"σ'(x)=σ(x)(1-σ(x))\", fontsize=20)\n",
    "plt.plot(x, sig(x)*(1-sig(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obliczanie gradientów\n",
    "Teraz mając pochodną funkcji sigmoidalnej i wiedząc jak działa regresja liniowa możemy zdefiniować regresję logistyczną i trenować podobnie jak w przypadku regresji liniowej! \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{y} & = \\sigma(w^Tx) \\\\\n",
    "\\hat{y} & = \\sigma(w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n) \\\\\n",
    "\\hat{y} & = \\sigma(w_0 + \\sum_{i=1}^n w_ix_i) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Aby wytrenować model należy na nowo policzyć gradienty z uzwględnieniem nowej funkcji kosztu i funkcji aktywacji (sigmoidalnej).\n",
    "\n",
    "## Funkcja kosztu\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x^i &= \\Reals^n \\\\\n",
    "h_\\theta(x) &= \\sigma(\\theta^Tx) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Funkcja kosztu musi być różniczkowalna i maksymalizować prawdopodobieństwo przynależności do danej klasy. W przypadku regresji logistycznej jest to funkcja logarytmu prawdopodobieństwa.\n",
    "\n",
    "Ze względu na binarność wejścia jest ona zdefiniowana w postaci warunku.\n",
    "$$\n",
    "J_\\theta(x, y) = \n",
    "\\begin{cases}\n",
    "-log(h_\\theta(x)) & \\text{if } y = 1 \\\\\n",
    "-log(1-h_\\theta(x)) & \\text{if } y = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Aby zapisać ją w postaci bardziej wektoryzowalnej można warunek zamienić na mnożenie i sumę.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "J_\\theta(x, y) &= -\\frac{1}{m} \\sum_{i=1}^m \n",
    "\\left[ \n",
    "    \\underbrace{y^i \\log(h_\\theta(x^i))}\n",
    "    _{\\text{if } y = 1} \n",
    "    + \n",
    "    \\underbrace{(1-y^i) \\log(1-h_\\theta(x^i))}\n",
    "    _{\\text{if } y = 0}\n",
    "\\right] \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## Gradient\n",
    "\n",
    "Dalej, należy tą funkcje zróżniczkować po $\\theta$ aby uzyskać gradienty.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} J_\\theta(x, y) &= \\frac{\\partial}{\\partial \\theta_j} \\left( -\\frac{1}{m} \\sum_{i=1}^m \\left[ y^i \\log(h_\\theta(x^i)) + (1-y^i) \\log(1-h_\\theta(x^i)) \\right] \\right) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Pierwszym krokiem jest wyjęcie sumy poza różniczkę i rozbicie na dwie części.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} J_\\theta(x, y) &= -\\frac{1}{m} \\sum_{i=1}^m \n",
    "\\left[\\frac{\\partial}{\\partial \\theta_j} \\left( y^i \\log(h_\\theta(x^i)) \\right) + \\frac{\\partial}{\\partial \\theta_j} \\left( (1-y^i) \\log(1-h_\\theta(x^i)) \\right) \n",
    "\\right] \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "I do uproszczenia zapisu zapiszemy jedynie część z logarytmem.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} & (   y^i  \\log(h_  \\theta(x^i))) & (1)\\\\\n",
    "\\frac{\\partial}{\\partial \\theta_j} & ((1-y^i) \\log(1-h_\\theta(x^i))) & (2)\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## Chain rule\n",
    "Pochodną $\\log(x)$ jest $\\frac{1}{x}$, a **chain rule** pozwala nam składać funkcje ze sobą:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial x} \\left( f(g(x)) \\right) &= f'(g(x)) \\cdot g'(x) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## Rozbicie na części\n",
    "\n",
    "W przypadku $(1)$ mamy:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} \\left( y^i \\log(h_\\theta(x^i)) \\right) &= y^i \\cdot \\frac{1}{h_\\theta(x^i)} \\cdot \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^i) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "W przypadku $(2)$ mamy:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} \\left( (1-y^i) \\log(1-h_\\theta(x^i)) \\right) &= (1-y^i) \\cdot \\frac{1}{1-h_\\theta(x^i)} \\cdot \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^i) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "Pochodną $h_\\theta(x)$ jest \n",
    "$\n",
    "    \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x) = \n",
    "    \\frac{\\partial}{\\partial \\theta_j} \\sigma(\\theta^T x)\n",
    "$ \n",
    "\n",
    "aby ją obliczyć trzeba użyć reguły łańcuchowej.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} h_\\theta(x) &= \\frac{\\partial}{\\partial \\theta_j} \\sigma(\\theta^T x) \\\\\n",
    "&= \\sigma(\\theta^T x) \\cdot (1 - \\sigma(\\theta^T x)) \\cdot \\frac{\\partial}{\\partial \\theta_j} \\theta^T x \\\\\n",
    "&= h_\\theta(x) \\cdot (1 - h_\\theta(x)) \\cdot x_j \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_j} \\theta^T x$ wynika z faktu że można zapisać jako sumę pochodnych \n",
    "$\\frac{\\partial}{\\partial \\theta_j} \\sum_{i=1}^n \\theta_i x_i =\n",
    " \\frac{\\partial}{\\partial \\theta_j} \\theta_1 x_1 + \n",
    " \\frac{\\partial}{\\partial \\theta_j} \\theta_2 x_2 + \n",
    " \\cdots + \n",
    " \\frac{\\partial}{\\partial \\theta_j} \\theta_n x_n = \n",
    " \\frac{\\partial}{\\partial \\theta_j} \\theta_j x_j = x_j$\n",
    "\n",
    "prawie wszystkie pochodne upraszczają się do zera poza $j$-tą.\n",
    "\n",
    "### Przypadek 1\n",
    "\n",
    "Mając tą informacje można zrobić podstawienie i uzyskać w $(1)$ przypadku:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} \\left( y^i \\log(h_\\theta(x^i)) \\right) \n",
    "&= y^i \\cdot \\frac{1}{h_\\theta(x^i)} \\cdot \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^i) \\\\\n",
    "&= y^i \\cdot \\frac{1}{h_\\theta(x^i)} \\cdot h_\\theta(x^i) \\cdot (1 - h_\\theta(x^i)) \\cdot x_j^i \\\\\n",
    "&= y^i \\cdot (1 - h_\\theta(x^i)) \\cdot x_j^i \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Przypadek 2\n",
    "\n",
    "W $(2)$ przypadku wynikiem jest:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} \\left( (1-y^i) \\log(1-h_\\theta(x^i)) \\right)\n",
    "&= (1-y^i) \\cdot \\frac{1}{1-h_\\theta(x^i)} \\cdot \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^i) \\\\\n",
    "&= (1-y^i) \\cdot \\frac{1}{1-h_\\theta(x^i)} \\cdot h_\\theta(x^i) \\cdot (1 - h_\\theta(x^i)) \\cdot x_j^i \\\\\n",
    "&= (1-y^i) \\cdot (-h_\\theta(x^i)) \\cdot x_j^i \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Po złożeniu $(1)$ i $(2)$ otrzymujemy:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} \\left( y^i \\log(h_\\theta(x^i)) + (1-y^i) \\log(1-h_\\theta(x^i)) \\right)\n",
    "&= y^i \\cdot (1 - h_\\theta(x^i)) \\cdot x_j^i + (1-y^i) \\cdot (-h_\\theta(x^i)) \\cdot x_j^i \\\\\n",
    "&= (h_\\theta(x^i) - y^i) \\cdot x_j^i \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Zapiszmy to jeszcze raz, na środku\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta_j} J_\\theta(x, y) = (h_\\theta(x^i) - y^i) \\cdot x_j^i\n",
    "$$\n",
    "\n",
    "**Gotowe!** teraz mając pochodną funkcji kosztu można aktualizować parametry $\\theta$ tak samo jak w przypadku regresji liniowej. Pochodna ma podobną postać do tej z regresji liniowej.\n",
    "\n",
    "## Wiele klas\n",
    "\n",
    "Predykcja multi-klasowa wymaga wytrenowania odpowiednio większej ilości modeli (jeden dla każdej klasy) gdzie każdy model będzie przewidywał czy próbka należy do jednej klasy lub nie. Dla przykładu w klasyfikacji cyfr (0-9) będzie to 10 modeli z których jeden będzie przewidywać czy dana cyfra jest `0` czy nie, drugi czy jest `1` czy nie itd. Wybiera się klasę dla której model przewidział największą wartość prawdopodobieństwa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie Labolatoryjne\n",
    "Najpierw import bibliotek. Jest to ten sam kod co na poprzednich labolatoriach z różniącą się funkcją printowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import sklearn as sk\n",
    "import sklearn.preprocessing as skp \n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.metrics as skm\n",
    "import sklearn.pipeline as skpl\n",
    "\n",
    "# Ulepszona funkcja do formatowania outputu z cellów na podstaiwe doświadczeń z poprzednich laboratoriów\n",
    "def displmd(*args, **kwargs):\n",
    "    display(Markdown('\\n\\n'.join(arg for arg in args), **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyczytwanie danych\n",
    "Moduł `pandas` pozwala na łatwe wczytywanie danych z pliku `*.csv`. Wczytujemy dane z pliku `credit_clients.csv` i wyświetlamy pierwsze 5 wierszy aby sprawdzić czy dane zostały poprawnie wczytane. Parametr `header` określa czy pierwszy wiersz pliku zawiera nazwy kolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(io='credit_clients.xls', header=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz można rozdzielić dane na cechy i etykiety. W tym przypadku cechami są wszystkie kolumny oprócz ostatniej, a etykietami jest ostatnia kolumna o nazwie `default payment next month`. Zawiera ona jedynie wartości 0 i 1, czyli perfekcyjny przypadek dla regresji logistycznej. Notacja `(30000,)` oznacza jeden wiersz, to samo co `(30000, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Rozmiar zbioru danych: `(30000, 24)`\n",
       "\n",
       "Rozmiar zbioru target: `(30000,)`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>167484.322667</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.853133</td>\n",
       "      <td>1.551867</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.701315e+04</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8660.398374</td>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>...</td>\n",
       "      <td>6.934939e+04</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.572640e+05</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7500.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666250e+03</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.008850e+04</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22500.250000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.016475e+04</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.664089e+06</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean   15000.500000   167484.322667      1.603733      1.853133      1.551867   \n",
       "std     8660.398374   129747.661567      0.489129      0.790349      0.521970   \n",
       "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
       "25%     7500.750000    50000.000000      1.000000      1.000000      1.000000   \n",
       "50%    15000.500000   140000.000000      2.000000      2.000000      2.000000   \n",
       "75%    22500.250000   240000.000000      2.000000      2.000000      2.000000   \n",
       "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean      35.485500     -0.016700     -0.133767     -0.166200     -0.220667   \n",
       "std        9.217904      1.123802      1.197186      1.196868      1.169139   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...     BILL_AMT3      BILL_AMT4      BILL_AMT5      BILL_AMT6  \\\n",
       "count  ...  3.000000e+04   30000.000000   30000.000000   30000.000000   \n",
       "mean   ...  4.701315e+04   43262.948967   40311.400967   38871.760400   \n",
       "std    ...  6.934939e+04   64332.856134   60797.155770   59554.107537   \n",
       "min    ... -1.572640e+05 -170000.000000  -81334.000000 -339603.000000   \n",
       "25%    ...  2.666250e+03    2326.750000    1763.000000    1256.000000   \n",
       "50%    ...  2.008850e+04   19052.000000   18104.500000   17071.000000   \n",
       "75%    ...  6.016475e+04   54506.000000   50190.500000   49198.250000   \n",
       "max    ...  1.664089e+06  891586.000000  927171.000000  961664.000000   \n",
       "\n",
       "            PAY_AMT1      PAY_AMT2      PAY_AMT3       PAY_AMT4  \\\n",
       "count   30000.000000  3.000000e+04   30000.00000   30000.000000   \n",
       "mean     5663.580500  5.921163e+03    5225.68150    4826.076867   \n",
       "std     16563.280354  2.304087e+04   17606.96147   15666.159744   \n",
       "min         0.000000  0.000000e+00       0.00000       0.000000   \n",
       "25%      1000.000000  8.330000e+02     390.00000     296.000000   \n",
       "50%      2100.000000  2.009000e+03    1800.00000    1500.000000   \n",
       "75%      5006.000000  5.000000e+03    4505.00000    4013.250000   \n",
       "max    873552.000000  1.684259e+06  896040.00000  621000.000000   \n",
       "\n",
       "            PAY_AMT5       PAY_AMT6  \n",
       "count   30000.000000   30000.000000  \n",
       "mean     4799.387633    5215.502567  \n",
       "std     15278.305679   17777.465775  \n",
       "min         0.000000       0.000000  \n",
       "25%       252.500000     117.750000  \n",
       "50%      1500.000000    1500.000000  \n",
       "75%      4031.500000    4000.000000  \n",
       "max    426529.000000  528666.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.iloc[:,:-1]\n",
    "target = data[\"default payment next month\"]\n",
    "\n",
    "displmd(\n",
    "    f\"Rozmiar zbioru danych: `{df.shape}`\",\n",
    "    f\"Rozmiar zbioru target: `{target.shape}`\",\n",
    ")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza tej kolumny pokazuje bardzo ważną informacje - ponad `75%` próbek to `0`, oznacza to że model ma ułatwione zadanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|       |   default payment next month |\n",
       "|:------|-----------------------------:|\n",
       "| count |                 30000        |\n",
       "| mean  |                     0.2212   |\n",
       "| std   |                     0.415062 |\n",
       "| min   |                     0        |\n",
       "| 25%   |                     0        |\n",
       "| 50%   |                     0        |\n",
       "| 75%   |                     0        |\n",
       "| max   |                     1        |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displmd(target.describe().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 24 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   ID         30000 non-null  int64\n",
      " 1   LIMIT_BAL  30000 non-null  int64\n",
      " 2   SEX        30000 non-null  int64\n",
      " 3   EDUCATION  30000 non-null  int64\n",
      " 4   MARRIAGE   30000 non-null  int64\n",
      " 5   AGE        30000 non-null  int64\n",
      " 6   PAY_0      30000 non-null  int64\n",
      " 7   PAY_2      30000 non-null  int64\n",
      " 8   PAY_3      30000 non-null  int64\n",
      " 9   PAY_4      30000 non-null  int64\n",
      " 10  PAY_5      30000 non-null  int64\n",
      " 11  PAY_6      30000 non-null  int64\n",
      " 12  BILL_AMT1  30000 non-null  int64\n",
      " 13  BILL_AMT2  30000 non-null  int64\n",
      " 14  BILL_AMT3  30000 non-null  int64\n",
      " 15  BILL_AMT4  30000 non-null  int64\n",
      " 16  BILL_AMT5  30000 non-null  int64\n",
      " 17  BILL_AMT6  30000 non-null  int64\n",
      " 18  PAY_AMT1   30000 non-null  int64\n",
      " 19  PAY_AMT2   30000 non-null  int64\n",
      " 20  PAY_AMT3   30000 non-null  int64\n",
      " 21  PAY_AMT4   30000 non-null  int64\n",
      " 22  PAY_AMT5   30000 non-null  int64\n",
      " 23  PAY_AMT6   30000 non-null  int64\n",
      "dtypes: int64(24)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 23) (6000, 23) (24000,) (6000,)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns=['ID'])\n",
    "y = target\n",
    "xy = pd.concat([x,y], axis=1)\n",
    "\n",
    "train_x, test_x, train_y, test_y = skms.train_test_split(x, y, test_size=0.2)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacja, Regresja i Ocena\n",
    "\n",
    "Poniżej wykonano normalizacje i trenowanie modelu regresji logistycznej.\n",
    "Jak widać po wynikach, model osiągnął dokładność na zbiorze treningowym wynoszącą około $81.2\\%$ jest to **jakaś** dokładność, patrząc na średnią wartość `default payment next month` wynoszącą $22.1\\%$ to model jest raczej kiepski. Nawet zgadując losowo, można uzyskać dokładność $77.9\\%$ (Odpowiadać na wszystkie wartości zerem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Model Accuracy\n",
       "\n",
       "Accuracy score: `0.8156666666666667`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlr = skpl.make_pipeline(skp.StandardScaler(), sklm.LogisticRegression())\n",
    "\n",
    "nlr.fit(train_x, train_y)\n",
    "\n",
    "acc_score = skm.accuracy_score(test_y, nlr.predict(test_x))\n",
    "\n",
    "displmd(\n",
    "    \"# Model Accuracy\",\n",
    "    f\"Accuracy score: `{acc_score}`\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Model output\n",
       "\n",
       "`Model output: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`\n",
       "\n",
       "`Ground truth: [0, 1, 0, 1, 0, 1, 0, 1, 0, 0]`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_y = nlr.predict(test_x[:10])\n",
    "groud_y = test_y[:10]\n",
    "\n",
    "displmd(\n",
    "    \"# Model output\",\n",
    "    f\"`Model output: {list(model_y)}`\",\n",
    "    f\"`Ground truth: {list(groud_y)}`\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowo zamiast wartości binarnych, można sprawdzić prawdopodobieństwa przynależności do danej klasy. W tym celu należy wywołać funkcję `predict_proba` zamiast `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Model output\n",
       "\n",
       "`Model output: 0.19 0.18 0.07 0.23 0.22 0.54 0.22 0.26 0.27 0.18`\n",
       "\n",
       "`Ground truth: 0.00 1.00 0.00 1.00 0.00 1.00 0.00 1.00 0.00 0.00`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_y = nlr.predict_proba(test_x[:10])\n",
    "groud_y = test_y[:10]\n",
    "\n",
    "displmd(\n",
    "    \"# Model output\",\n",
    "    f\"`Model output: {' '.join([f'{_y[1]:0.2f}' for _y in model_y])}`\",\n",
    "    f\"`Ground truth: {' '.join([f'{_y:0.2f}' for _y in groud_y])}`\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartości te można policzyć ręcznie korzystając z `coef_` i `intercept_`. Należy pamiętać o normalizacji danych!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Model output (manual)\n",
       "\n",
       "`Model output: 0.19 0.18 0.07 0.23 0.22 0.54 0.22 0.26 0.27 0.18`\n",
       "\n",
       "`Treshold    : 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00`\n",
       "\n",
       "`Ground truth: 0.00 1.00 0.00 1.00 0.00 1.00 0.00 1.00 0.00 0.00`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculating output manulay using _coef and _intercept\n",
    "_coef = nlr.named_steps['logisticregression'].coef_\n",
    "_intercept = nlr.named_steps['logisticregression'].intercept_\n",
    "_x_norm = nlr.named_steps['standardscaler'].transform(test_x[:10])\n",
    "\n",
    "model_y = sig(_coef @ _x_norm.T + _intercept)\n",
    "groud_y = test_y[:10]\n",
    "\n",
    "displmd(\n",
    "    \"# Model output (manual)\",\n",
    "    f\"`Model output: {' '.join([f'{_y:0.2f}' for _y in model_y[0]])}`\",\n",
    "    f\"`Treshold    : {' '.join(['1.00' if _y > 0.5 else '0.00' for _y in model_y[0]])}`\",\n",
    "    f\"`Ground truth: {' '.join([f'{_y:0.2f}' for _y in groud_y])}`\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać po macierzy model rzeczywiście najczęściej obstawia wartość `0` co kończy się dużą ilością pomyłek dla w przypadku gdy etykieta jest `1`. Wysoka dokładność nie oznacza że model jest dobry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x23102c49b80>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skm.ConfusionMatrixDisplay.from_predictions(test_y, nlr.predict(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzanie cross walidacji nie wykazuje żadnych ciekawych zależności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Cross-validation results\n",
       "\n",
       "Accuracy: 0.81 ± 0.01\n",
       "\n",
       "Train accuracy: 0.81 ± 0.00\n",
       "\n",
       "## All results\n",
       "\n",
       "|    |   test_score |   train_score |\n",
       "|---:|-------------:|--------------:|\n",
       "|  0 |     0.803333 |      0.811963 |\n",
       "|  1 |     0.800333 |      0.812259 |\n",
       "|  2 |     0.807667 |      0.811037 |\n",
       "|  3 |     0.804    |      0.812    |\n",
       "|  4 |     0.809333 |      0.810222 |\n",
       "|  5 |     0.816667 |      0.809778 |\n",
       "|  6 |     0.825    |      0.80863  |\n",
       "|  7 |     0.807667 |      0.810481 |\n",
       "|  8 |     0.811333 |      0.810074 |\n",
       "|  9 |     0.811667 |      0.810444 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run cross-validation\n",
    "cv = skms.cross_validate(nlr, df, target, cv=10, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "displmd(\n",
    "\"## Cross-validation results\",\n",
    "\"Accuracy: {:.2f} ± {:.2f}\".format(cv['test_score'].mean(), cv['test_score'].std()),\n",
    "\"Train accuracy: {:.2f} ± {:.2f}\".format(cv['train_score'].mean(), cv['train_score'].std()),\n",
    "\"## All results\",\n",
    "pd.DataFrame(cv)[[\"test_score\", \"train_score\"]].to_markdown()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna bez normalizacji\n",
    "Regresja logistyczna powinna działać dobrze bez normalizacji, ale proces uczenia jest trudniejszy, `sklearn` wyświatla **warning** że nie udało się osiągnąć zbieżności (zależne od run'a). Uruchomienie uczenia z większą ilością kroków usuwa definitywnie usunie warning ale nie poprawia wyniku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maciej\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Logistic Regression without scaling\n",
       "\n",
       "Accuracy: `0.7823`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlrns = skpl.make_pipeline(sklm.LogisticRegression())\n",
    "nlrns.fit(train_x, train_y)\n",
    "displmd(\n",
    "    \"## Logistic Regression without scaling\",\n",
    "    \"Accuracy: `{:.4f}`\".format(skm.accuracy_score(test_y, nlrns.predict(test_x))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Logistic Regression without scaling **`(max_iter=1000)`**\n",
       "\n",
       "Accuracy: `0.7823`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlrns = skpl.make_pipeline(sklm.LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "nlrns.fit(train_x, train_y)\n",
    "displmd(\n",
    "    \"## Logistic Regression without scaling **`(max_iter=1000)`**\",\n",
    "    \"Accuracy: `{:.4f}`\".format(skm.accuracy_score(test_y, nlrns.predict(test_x))),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przeszukiwanie przestrzeni parametrów\n",
    "\n",
    "`sklearn` posiada narzędzie do przeszukiwania przestrzeni parametrów, które jest bardzo przydatne przy uczeniu modeli. Można podać zakresy i parametry jakie chcemy sprawdzić a model sam sprawdzi wszystkie kombinacje i zapisze wyniki każdego z nich.\n",
    "Jest to równoznaczne z wykonaniem pętli po wszystkich kombinacjach parametrów i zapisanie wyników `cross_validation` dla każdej z nich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maciej\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.01, 0.1, 1, 10],\n",
       "                         'logisticregression__penalty': ['l1', 'l2'],\n",
       "                         'logisticregression__solver': ['liblinear', 'saga']},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! UWAGA: NIE URUCHAMIAĆ TEJ KOMÓRKI, DłUGO SIĘ LICZY !\n",
    "# grid_search params\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10],\n",
    "    'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__solver': ['liblinear', 'saga'],\n",
    "}\n",
    "# setup grid search\n",
    "grid = skms.GridSearchCV(nlr, param_grid, cv=5, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "# run grid search\n",
    "grid.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po fakcie można sprawdzić najlepsze parametry korzystając z `best_params_` oraz najlepszy wynik `best_score_`. W tym przypadu `LigisticRegression` radzi sobie w każdym przypadku źle i przeszukiwanie przestrzeni hiper-parametrów nie ma sensu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Grid search results\n",
       "\n",
       "Best accuracy: `0.8082`\n",
       "\n",
       "Best params: \n",
       "```py \n",
       "{'logisticregression__C': 10, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displmd(\n",
    "    \"## Grid search results\",\n",
    "    \"Best accuracy: `{:.4f}`\".format(grid.best_score_),\n",
    "    f\"\"\"Best params: \n",
    "```py \n",
    "{grid.best_params_}\n",
    "```\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## All results\n",
       "\n",
       "|    | score           | params                                                                                                            |\n",
       "|---:|:----------------|:------------------------------------------------------------------------------------------------------------------|\n",
       "| 13 | 0.80825±3.4e-03 | `{'logisticregression__C': 10, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}`        |\n",
       "| 15 | 0.80825±3.4e-03 | `{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'saga'}`        |\n",
       "|  6 | 0.80821±3.6e-03 | `{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}`  |\n",
       "|  7 | 0.80821±3.4e-03 | `{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'saga'}`       |\n",
       "| 11 | 0.80812±3.4e-03 | `{'logisticregression__C': 1, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'saga'}`         |\n",
       "|  9 | 0.80808±3.4e-03 | `{'logisticregression__C': 1, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}`         |\n",
       "| 14 | 0.80800±3.3e-03 | `{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}`   |\n",
       "| 10 | 0.80796±3.4e-03 | `{'logisticregression__C': 1, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}`    |\n",
       "| 12 | 0.80796±3.4e-03 | `{'logisticregression__C': 10, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}`   |\n",
       "|  8 | 0.80783±3.4e-03 | `{'logisticregression__C': 1, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}`    |\n",
       "|  2 | 0.80775±3.1e-03 | `{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}` |\n",
       "|  4 | 0.80771±3.3e-03 | `{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}`  |\n",
       "|  5 | 0.80763±3.3e-03 | `{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}`       |\n",
       "|  3 | 0.80708±2.8e-03 | `{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'saga'}`      |\n",
       "|  0 | 0.80554±2.4e-03 | `{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}` |\n",
       "|  1 | 0.80483±2.3e-03 | `{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}`      |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvres = grid.cv_results_\n",
    "displmd(\n",
    "    \"## All results\",\n",
    "    pd.DataFrame(cvres)[[\"mean_test_score\", \"std_test_score\", \"params\"]]\n",
    "    .sort_values(by=\"mean_test_score\", ascending=False)\n",
    "    .apply(lambda x: ({\"score\": f\"{x[0]:.5f}±{x[1]:.1e}\", \"params\": f\"`{x[2]}`\"}), axis=1, result_type='expand') #type: ignore\n",
    "    .to_markdown()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Może zbiór uczący 50/50?\n",
    "\n",
    "Wytrenwanie modelu na pełnym zbiorze wymusi na modelu uczenie się na danych niezbalansowanych. Może lepiej będzie trenować model na zbiorze uczącym w którym jest równo próbek z każdej klasy?\n",
    "\n",
    "Wygenerujmy dane i sprawdźmy jak model radzi sobie na takim zbiorze w porównaniu starego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10617.000000\n",
       "mean         0.496468\n",
       "std          0.500011\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get x values so there is 50% y equal to 1 and 50% y equal to 0   \n",
    "# split data into 2 groups\n",
    "x1 = x[y == 1]\n",
    "x0 = x[y == 0]\n",
    "\n",
    "ones_count = x1.shape[0]\n",
    "# get ones_count random values from 0 group \n",
    "x0 = x0.sample(ones_count)\n",
    "\n",
    "# concat groups\n",
    "x_2 = pd.concat([x1, x0], axis=0)\n",
    "y_2 = pd.concat([pd.Series([1] * ones_count), pd.Series([0] * ones_count)], axis=0)\n",
    "\n",
    "# split to train and test\n",
    "train_x_2, test_x_2, train_y_2, test_y_2 = skms.train_test_split(x_2, y_2, test_size=0.2)\n",
    "\n",
    "# mean of y should be ~0.5\n",
    "train_y_2.describe() #type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Grid search results\n",
       "\n",
       "Best accuracy: `0.6869`\n",
       "\n",
       "Best params:\n",
       "```py\n",
       "{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train model & do grid search\n",
    "nlr_2 = skpl.make_pipeline(skp.StandardScaler(), sklm.LogisticRegression(max_iter=100))\n",
    "grid_2 = skms.GridSearchCV(nlr_2, param_grid, cv=5, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "grid_2.fit(train_x_2, train_y_2)\n",
    "\n",
    "displmd(\n",
    "    \"## Grid search results\",\n",
    "    \"Best accuracy: `{:.4f}`\".format(grid_2.best_score_),\n",
    "    f\"\"\"Best params:\n",
    "```py\n",
    "{grid_2.best_params_}\n",
    "```\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Accuracy comparison\n",
       "\n",
       "|                     |      All |   Balanced |\n",
       "|:--------------------|---------:|-----------:|\n",
       "| Trained on all      | 0.815667 |   0.590207 |\n",
       "| Trained on balanced | 0.724833 |   0.672316 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x23101a32190>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = pd.DataFrame(columns=[\"All\", \"Balanced\"], index=[\"Trained on all\", \"Trained on balanced\"])\n",
    "\n",
    "mat.loc[\"Trained on all\", \"All\"] = skm.accuracy_score(test_y, grid.predict(test_x))\n",
    "mat.loc[\"Trained on all\", \"Balanced\"] = skm.accuracy_score(test_y_2, grid.predict(test_x_2))\n",
    "mat.loc[\"Trained on balanced\", \"All\"] = skm.accuracy_score(test_y, grid_2.predict(test_x))\n",
    "mat.loc[\"Trained on balanced\", \"Balanced\"] = skm.accuracy_score(test_y_2, grid_2.predict(test_x_2))\n",
    "\n",
    "displmd(\n",
    "    \"## Accuracy comparison\",\n",
    "    mat.to_markdown(),\n",
    ")\n",
    "skm.ConfusionMatrixDisplay.from_predictions(test_y, grid_2.predict(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać oba modele radzą sobie źle na zbalansowanych danych, ale model na nich trenowany znacznie lepiej. Model trenowany na zbiorze niezbalansowanym ma również gorszy wynik na całym zbiorze ale wynika to z tego że nie jest **zbiasowany** przez przewagę próbek z klasy `0`. \n",
    "\n",
    "Po `confusion_matrix` można zauważyć że model trenowany na zbalansowanym zbiorze ma dużo mniej pewności do której klasy należy próbka, w porównaniu ze starym modelem który mógł z góry założyć że próbka prawdobodobnie należy do klasy `0`.\n",
    "\n",
    "Dodatkowo wyniki drugiego modelu są bardziej stabline - wydajność oscyluje w okolicy `70%` a nie jak w przypadku pierwszego modelu gdzie wynik osiąga `80%` dla całego zbioru ale `60%` dla zbalansowanego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski\n",
    "* Regresja logistyczna jest bardzo podobna do regresji liniowej, różni się jedynie funkcją aktywacji i koncepcją regresji wieloklasowej.\n",
    "* Regresja liniowa nie nadaje się do tego problemu (za mała dokładność)\n",
    "* Wyprowadzanie funkcji sigmoidalnej z użyciem `latex'u` to zły pomysł\n",
    "* Ostrożnie dobierać parametry do przeszukiwania bo czasami może to być bardzo długo trwający proces\n",
    "* Trenowanie na danych znormalizowanych jest szybsze (otpymalizator lepiej sobie radzi)\n",
    "* Modele są czułe na balans danych"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3f3c870ccc3fe58f140ce64581ec8eaa0605a9d9788d0734c700f5795092453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
